# scripts/run_batches.py
import os
import json
import pathlib
from typing import List, Dict

import pandas as pd
from openai import OpenAI

MODEL = "gpt-4o"  # Responses API model
OUTDIR = pathlib.Path("build")
OUTDIR.mkdir(parents=True, exist_ok=True)


def load_companies(path_xlsx: str = "data/companies.xlsx") -> List[Dict]:
    # locate your Excel file (supports companies10.xlsx too)
    xpaths = [path_xlsx, "data/companies10.xlsx"]
    xfile = next((p for p in xpaths if os.path.exists(p)), None)
    if not xfile:
        raise FileNotFoundError("Expected data/companies.xlsx (or data/companies10.xlsx)")

    # read Excel via openpyxl
    df = pd.read_excel(xfile, engine="openpyxl")  # pandas read_excel uses openpyxl for .xlsx :contentReference[oaicite:0]{index=0}
    df.columns = [str(c).strip() for c in df.columns]

    required = ["Company", "BSE_Code"]
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise ValueError(f"Missing columns in {xfile}: {missing}. Need at least Company and BSE_Code.")

    def to_code(v):
        if pd.isna(v): return ""
        try:
            return str(int(v))  # avoid '543693.0'
        except Exception:
            return str(v).strip()

    rows: List[Dict] = []
    for _, r in df.iterrows():
        name = str(r["Company"]).strip()
        bse_code = to_code(r["BSE_Code"])
        bse_sym  = str(r.get("BSE_Symbol", "")).strip()
        nse_sym  = str(r.get("NSE_Symbol", "")).replace(".NS", "").strip()

        # Prefer numeric BSE code (works reliably on Screener),
        # else fall back to NSE symbol (without .NS), then BSE symbol.
        slug_or_code = bse_code or nse_sym or bse_sym
        rows.append({"name": name, "slug_or_code": slug_or_code})

    return rows

def call_llm_for_batch(client: OpenAI, batch_id: int, companies: List[Dict]):
    try:
        # We still call it "batch" for compatibility, but we pass ALL companies
        user_payload = {
            "batch_id": batch_id,
            "companies": companies,
            "out_pdf": "AllCompanies_Report.pdf",
            "out_csv": "AllCompanies_Quarterly.csv",
        }
        
        print(f"Making Responses API call with model: {MODEL}")
        print(f"User payload: {len(companies)} companies")

        resp = client.responses.create(
            model=MODEL,
            tools=[{"type": "web_search"},{"type": "code_interpreter", "container": {"type": "auto"}}],
            input=[
                {"role": "system", "content": open("prompts/PROMPT.md", "r", encoding="utf-8").read()},
                {"role": "user", "content": json.dumps(user_payload)},
            ],
        )

        print(f"Response received. Processing output files...")

        # Download files produced by Code Interpreter
        saved = []
        for item in (resp.output or []):
            for c in getattr(item, "content", []) or []:
                if getattr(c, "type", "") == "output_file" and getattr(c, "file_id", None):
                    try:
                        fmeta = client.files.retrieve(c.file_id)
                        fname = fmeta.filename or f"batch_{batch_id}_{c.file_id}"
                        out_path = OUTDIR / fname
                        print(f"Downloading file: {fname} -> {out_path}")
                        with client.files.with_streaming_response.download(c.file_id) as stream:
                            stream.stream_to_file(out_path)
                        saved.append(out_path)
                        print(f"✓ Saved: {out_path} ({out_path.stat().st_size} bytes)")
                    except Exception as e:
                        print(f"Error downloading file {c.file_id}: {e}")
        
        if not saved:
            print("Warning: No files were generated by the LLM")
            
        return saved
        
    except Exception as e:
        print(f"Error in call_llm_for_batch: {e}")
        import traceback
        traceback.print_exc()
        raise


def main():
    try:
        if not os.environ.get("OPENAI_API_KEY"):
            raise ValueError("OPENAI_API_KEY environment variable is required")
        
        client = OpenAI()  # needs OPENAI_API_KEY
        print(f"Loading companies...")
        companies = load_companies()
        print(f"Found {len(companies)} companies")
        
        print(f"Calling LLM for batch processing...")
        saved = call_llm_for_batch(client, 1, companies)
        print("[all] saved:", [str(p) for p in saved])

        print("\nArtifacts in build/:")
        for p in sorted(OUTDIR.glob("*")):
            print(" -", p)
            
        # Verify expected files exist
        expected_files = ["AllCompanies_Report.pdf", "AllCompanies_Quarterly.csv"]
        for fname in expected_files:
            fpath = OUTDIR / fname
            if fpath.exists():
                print(f"✓ {fname} created successfully ({fpath.stat().st_size} bytes)")
            else:
                print(f"✗ {fname} NOT FOUND")
                
    except Exception as e:
        print(f"Error in main(): {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()
